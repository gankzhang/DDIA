深度学习在推荐系统中的应用

[TOC]

### 推荐系统的作用

- ==解决信息过载==，用户高效获取感兴趣的问题
- 提高用户转化率，得到商业目标增长

### 推荐系统的架构

#### 逻辑框架

- 对于用户U，在特定场景C下，针对海量物品信息，构建函数f(U,I,C)，预测用户对特定候选物品I的喜好程度
- 根据喜好程度对所有候选物品筛选，排序，生成推荐列表

#### 技术架构

##### 数据部分

- 数据如何获得，存储，更新和处理
- 客户端/服务器端实时数据处理，
  - 流处理平台Flink
  - 大数据平台Spark。
- 区分三类信息，用户信息，物品信息，场景信息
- 特征工程
  - 数值特征的 归一化/离散化/非线性变化，
  - ID（离散）特征的 onehot编码/Embedding
  - 特征组合
- 用户特征：用户行为，社交关系，属性标签
- 物品特征：内容类数据，属性表情，第三方信息
- 场景特征：时间，地点，页面场景

##### 模型部分

- 

在拿到推荐系统的原始数据之后，推荐系统会进一步加工，数据出口有三个

- 生成推荐模型锁需要的样本数据，用于算法模型的训练和评估
- 生成推荐模型服务（model serving）所需的「特征」，用于推荐系统的线上推断
- 生成系统监控、商业智能（Business Intelligence，BI）所需的统计数据

推荐系统「模型部分」是推荐系统的主题，一般由「召回层」「排序」「补充策略与算法层」组成。

- 召回层：利用高效的召回规则、算法或简单模型，快速从海量的候选集召回用户可能感兴趣的物品
- 排序层：利用排序模型对初筛的候选集进行精排序
- 补充策略与算法：也被称为再排序层，在推荐列表返回用户之前，兼顾结果的多样性、流行度、新鲜度等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐里列表。

### 推荐系统的进化(DL之前)

传统推荐模型的发展主要经历了四个阶段：

- **协同过滤 CF 算法阶段** ：只需用户物品共现矩阵就可以构建推荐系统，根据相似度取值对象可分为 itemCF 和 userCF 两类，优势是简单易实现。CF 的问题是泛化能力弱，无法应对稀疏矩阵，而矩阵分解作为协同过滤的进化版，克服了 CF 的缺点。
- **逻辑回归 LR 阶段** ：综合利用用户、物品、上下文等多种不同的特征，假设用户是否点击广告服从伯努利分布，将推荐问题转化为点击率预估 (CTR) 问题，预测正样本概率对物品进行排序。其数学形式是各个特征的加权和经过 sigmoid 函数，得到用户点击物品的概率。LR 的优势是可解释性强、易于并行化、模型简单、训练开销小。其局限性在于表达能力不强，需要大量具有业务背景知识的人工特征筛选与交叉。
- **因子分解机 FM 阶段** ：为每个特征学习一个隐向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。虽然 FM 相比 POLY2 的完全交叉 + 单一权重记忆能力略弱，但解决了特征交叉过程中交叉特征对应的数据过于稀疏无法充分学习权重的问题。FFM 引入特征域进一步增强了模型的表达能力，做特征交叉时，每个特征选择与对方域对应的隐向量的内积作为交叉特征的权重，但 FFM 的计算复杂度也由 kn 上升到 kn*n。
- **组合模型阶段** ：这一阶段主要是为了进一步提高特征交叉的维度，同时融合多个模型的优点。GBDT+LR 是组合模型的代表方案，GBDT 自动进行特征筛选和组合得到新的离散特征向量输入 LR 模型。GBDT+LR 的组合方式开启了特征工程模型化的趋势，真正实现端到端训练。

### 深度学习在推荐系统中的应用

两类思路：

- 特征工程自动化的思路：PNN，Wide&Deep，Deep&Cross，FNN，DeepFM，NFM
- 模型结构的尝试：Attention，序列模型，强化学习

深度学习的推荐模型从多层感知机MLP出发，有七个演变方向：

- 改变神经网络的复杂程度

- 丰富特征交叉方式：改变特征变量的交叉方式

- 组合模型

- FM模型的深度学习演化

- 引入Attention机制：包括AFM（Attention Factorization Machine）和DIN（Deep Interest Network）

- 融合序列模型，模拟用户行为和兴趣的演化趋势

- 结合强化学习

  

### Embedding在推荐系统中的应用

embedding用低维稠密的向量表示一个对象（object），向量能表达相应对象的某些特征，向量之间的距离也表示了物品的相似性

Embedding的重要性体现：

- 对one-hot编码的处理需要低维稠密表示
- Embedding本身是重要的特征向量
- 对物品，用户相似度的计算可以用于召回层，为局部敏感哈希等快速最近邻搜索技术应用推荐系统提供了基础

#### 从Word2vec到item2vec

Word2vec是经典的生成词向量的方法，item2vec（2017微软论文）运用负采样，以item出现在同一集合为正例，否则为负例生成embedding。同一集合的一个例子：用户同一订单下的商品。这种方法将embedding扩展到各种可以生成sequence的领域。

KDD2018最佳论文，Airbnb的item2vec：

- Listing Embedding：用户30分钟内连续点击的房源具有相似性，用skip-gram模型学习
- 将最终预定的房源视为强信息，作为全局context
- 对相同market的房源负采样负例

一般来说，由于推荐系统的物品库非常巨大，远超NLP中的词表，因此训练开销也很巨大，embedding层的训练在这里往往独立于主网络。

#### 基于图结构的embedding

- DeepWalk：在图上随机游走，产生物品序列，然后使用Word2vec

#### 局部敏感hash

- 基本思想是让相邻的点落入同一个桶，但既然源空间大于目标空间，距离就无法完全维持，因此这种局部敏感是相对的
- 本质上哈希函数是一个降维函数，数据从信息量大的高维降到低维。

### 特征工程

#### 推荐系统常用的特征

- 用户行为数据

  - 显式反馈：明确的评分，喜欢/不喜欢
  - 隐式反馈：浏览，各种行为时长
  - 前者数量小但含义明确，实时获取。后者数量大但含义不明确，需要分析后使用

- 用户关系数据

- 显性属性，标签数据

- 内容类数据（需要通过NLP，CV等手段转化）

- 上下文信息

  - ###### 描述推荐行为的场景，如时间地点，月份，社会事件，天气等等

  - 最典型的例子是季节和商品的关系，人们夏天吃冰淇淋，冬天吃火锅

  - 给某个用户推荐过的物品某种程度上不应该再推荐，也即时间多样性

- 统计类特征：历史CTR等

- 组合特征

#### 数值特征的处理

- 如果数据的分布符合某种分布，如高斯分布，可以使用损失函数
- 有时太多的精度只是噪声，**截断**使其成为类别特征
- 一些计数特征可以快速累加，可以标示是否存在为二值变量，或者分桶。
- 标准化（缩放）
- 对缺失值补均值或中位数，或者编码一个缺失数
- 统计量，如均值，方差，偏度，峰度，正负值比例。

#### 类别特征的处理

- 类别特征每一个可能的选项就可以表示为一个特征，如果这样则特征的数量会很大。这些特征有可能带有长尾属性，如大部分用户聚集在一些区域，大部分订单流向头部商家，这都是经济中自然存在的长尾分布。
- 树结构的模型处理类别特征效果较好，而且不需要降维等减少特征数的方法，因为特征类别多在树模型中只需要增加树的深度，且长尾部分此时也不会产生过拟合
- 



### 各个重要的属性

#### Parameter Server的分布式训练

- 分布式训练自然包括两个部分，server group和多个worker group
- Parameter Server的主要模式还是异步非阻断的
- 用一致性hash，利用range pull和range push等工程手段实现信息的最小传递
- 

#### 增加实时性

- 模型训练最常用的是**全量更新**，即利用某段时间内所有的训练样本进行重新训练，在替代旧的模型，这所需的时间往往较长，在离线的大数据平台上训练
- 增量更新指仅将新加入的样本喂入模型进行增量学习，往往在增加数据不多的情况下效果较好，但几轮之后就需要重新全局更新
- 在线学习指每获得一个新样本就更新模型，模型在设计时也考虑不断获取新数据
- 模型局部更新：降低训练效率低的部分的更新频率，如facebook的GBDT+LR。其中前者较少更新而后者经常更新
- 客户端模型更新：与用户有关的部分数据可以在客户端完成，比如实时更改用户的embedding，完成实时推荐（还在探索阶段）
- RALM模型：腾讯用于微信看一看实时推荐的模型
  - 基于一定的算法找到目标用户中和种子用户相似的用户，将对应种子用户喜欢的广告投放给他们
  - 基于相似用户的推荐对长尾内容表现较好，因为这种方式不依赖内容本身的特征
  - 

#### 多目标排序

- 有多个目标函数时，要找到一种排序方法使得多个目标都达到整体最优
- 之所以需要多目标，是因为推荐系统中（决定性的）显式反馈较少，需要各个隐式反馈来推荐，各个指标各自评价用户满意度和对企业效用的时候存在偏差
  - 目标偏差：电商直播的目标是购买，购买目标自然高于观看超过20s这个目标，但在短视频兼做电商的应用中可能反之。
  - 物品偏差：如果评价指标单一容易偏向某一类型的物品。如点击率偏向标题党，视频播放完成率偏向未完成视频，评论率偏向引战视频，用户浏览时间偏向新奇物品。
  - 用户偏差：不同用户表达满意度的方式不同，有的用户从不评论，或者从不点赞，或者从不收藏。



- 大概有四种解决方案：改变样本权重，多模型分数融合，排序学习，多任务学习
  - 改变样本权重：点击和分享都算作正样本，在CTR模型中作为训练数据。这样基本一定比只优化其中一个目标效果差，本质上就是目标加权折算
  - 多模型分数融合：用各个行为数据各自预测一个分数，最后在test/serving阶段加权融合。在serving时分数融合是通用操作，模型融合的超参数难以学习。
  - 排序学习：直接预测物品两两之间相对顺序
- 多任务学习
  - 学习器在不知道具体目标的情况下同时学习多个任务
  - 参数硬共享：前面的层都共享，之后最后一层全连接针对不同任务，最后做线性融合
  - 参数软共享：每个task有独立的特征提取层，但用一个正则化一类的方式来拉近模型参数的距离
  - ESMM：CVR是主任务，但也用CTR的任务来辅助训练，用共同目标来抵消样本选择偏差
  - MMOE

#### 冷启动的解决方法

- 主要有三大类：用户冷启动，物品冷启动，系统冷启动
- 冷启动策略：
  - 利用注册信息做粗粒度的个性化
  - 利用其它社交网络的好友做协同过滤
  - 注册时做粗反馈
  - 物品可以利用内容信息和相似的物品
- 冷启动的主要问题在于推荐系统的很多参数更新代价很大，用户行为数据量很大，因此难以频繁更新，但是冷启动就是需要快速迭代更新的。
- 在一个主要依赖推荐系统的网站，这是一个“探索与利用”问题
  - 传统的方法是简化为多臂老虎机问题，利用e-Greedy，Thompson，Sampling，UCB等方法。但是没有办法引入用户的上下文和个性化信息。
  - 个性化方法：如LinUCB
  - 基于模型的方法，如DRN中的探索网络

### 推荐系统的评估

- 线上AB test是昂贵的，影响部分用户体验，只能很小范围使用
- 线下的评估多种多样，但是线上的评估却很困难简单实现，而又不伤害用户体验
- 线下评估
  - holdout检验
  - 交叉验证
  - 自助法
  - Replay：逐一样本回放的精确线上仿真过程
- 采用最近的一次数据作为测试集可以避免引入future information，即用未来的数据预测过去，这不符合问题定义。



### 推荐系统的线上Serving

#### 基本解决方案

- 线上Serving，就是讲训练好的模型部署在线上的生产环境，进行实时的inference
- 前面所说的大量方法聚焦于利用离线数据，设计并训练模型，以及业务本身带来的模型设计（如冷启动，实时性）。但线上的应用还有性能和资源问题需要解决。
- 常见解决方案包括：自研平台，预训练Embedding+轻量级模型
- PMML全称Predictive Model Markup Language，常被用于中间媒介连接离线训练平台和线上预测平台。
- TensorFlow Serving等原生平台。
- Flask或者Django来写服务api，性能较低



### 参考资料

http://www.python88.com/topic/62566

https://amylewis.github.io/2020/07/21/Rec_sys_book_reading/index.html





第1章 互联网的增长引擎——推荐系统

- 1.1 为什么推荐系统是互联网的增长引擎
  - 1.1.1 推荐系统的作用和意义
  - 1.1.2 推荐系统与YouTube的观看时长增长
  - 1.1.3 推荐系统与电商网站的收入增长
- 1.2 推荐系统的架构
  - 1.2.1 推荐系统的逻辑框架
  - 1.2.2 推荐系统的技术架构
  - 1.2.3 推荐系统的数据部分
  - 1.2.4 推荐系统的模型部分
  - 1.2.5 深度学习对推荐系统的革命性贡献
  - 1.2.6 把握整体，补充细节
- 1.3 本书的整体结构



第2章 前深度学习时代——推荐系统的进化之路

- 2.1 传统推荐模型的演化关系图
- 2.2 协同过滤——经典的推荐算法
  - 2.2.1 什么是协同过滤
  - 2.2.2 用户相似度计算
  - 2.2.3 终结果的排序
  - 2.2.4 ItemCF
  - 2.2.5 UserCF与ItemCF的应用场景
  - 2.2.6 协同过滤的下一步发展
- 2.3 矩阵分解算法——协同过滤的进化
  - 2.3.1 矩阵分解算法的原理
  - 2.3.2 矩阵分解的求解过程
  - 2.3.3 消除用户和物品打分的偏差
  - 2.3.4 矩阵分解的优点和局限性
- 2.4 逻辑回归——融合多种特征的推荐模型
  - 2.4.1 基于逻辑回归模型的推荐流程
  - 2.4.2 逻辑回归模型的数学形式
  - 2.4.3 逻辑回归模型的训练方法
  - 2.4.4 逻辑回归模型的优势
  - 2.4.5 逻辑回归模型的局限性
- 2.5 从FM到FFM——自动特征交叉的解决方案
  - 2.5.1 POLY2模型——特征交叉的开始
  - 2.5.2 FM模型——隐向量特征交叉
  - 2.5.3 FFM模型——引入特征域的概念
  - 2.5.4 从POLY2到FFM的模型演化过程
- 2.6 GBDT+LR——特征工程模型化的开端
  - 2.6.1 GBDT+LR组合模型的结构
  - 2.6.2 GBDT进行特征转换的过程
  - 2.6.3 GBDT+LR 组合模型开启的特征工程新趋势
- 2.7 LS-PLM——阿里巴巴曾经的主流推荐模型
  - 2.7.1 LS-PLM 模型的主要结构
  - 2.7.2 LS-PLM模型的优点
  - 2.7.3 从深度学习的角度重新审视LS-PLM模型
- 2.8 总结——深度学习推荐系统的前夜



第3章 浪潮之巅——深度学习在推荐系统中的应用

- 3.1 深度学习推荐模型的演化关系图
- 3.2 AutoRec——单隐层神经网络推荐模型
  - 3.2.1 AutoRec模型的基本原理
  - 3.2.2 AutoRec模型的结构
  - 3.2.3 基于AutoRec模型的推荐过程
  - 3.2.4 AutoRec模型的特点和局限性
- 3.3 Deep Crossing模型——经典的深度学习架构
  - 3.3.1 Deep Crossing模型的应用场景
  - 3.3.2 Deep Crossing模型的网络结构
  - 3.3.3 Deep Crossing模型对特征交叉方法的革命
- 3.4 NeuralCF模型——CF与深度学习的结合
  - 3.4.1 从深度学习的视角重新审视矩阵分解模型
  - 3.4.2 NeuralCF模型的结构
  - 3.4.3 NeuralCF模型的优势和局限性
- 3.5 PNN模型——加强特征交叉能力
  - 3.5.1 PNN模型的网络架构
  - 3.5.2 Product层的多种特征交叉方式
  - 3.5.3 PNN模型的优势和局限性
- 3.6 Wide&Deep 模型——记忆能力和泛化能力的综合
  - 3.6.1 模型的记忆能力与泛化能力
  - 3.6.2 Wide&Deep模型的结构
  - 3.6.3 Wide&Deep模型的进化——Deep&Cross模型
  - 3.6.4 Wide&Deep模型的影响力
- 3.7 FM与深度学习模型的结合
  - 3.7.1 FNN——用FM的隐向量完成Embedding层初始化
  - 3.7.2 DeepFM——用FM代替Wide部分
  - 3.7.3 NFM——FM的神经网络化尝试
  - 3.7.4 基于FM的深度学习模型的优点和局限性
- 3.8 注意力机制在推荐模型中的应用
  - 3.8.1 AFM——引入注意力机制的FM
  - 3.8.2 DIN——引入注意力机制的深度学习网络
  - 3.8.3 注意力机制对推荐系统的启发
- 3.9 DIEN——序列模型与推荐系统的结合
  - 3.9.1 DIEN的“进化”动机
  - 3.9.2 DIEN模型的架构
  - 3.9.3 兴趣抽取层的结构
  - 3.9.4 兴趣进化层的结构
  - 3.9.5 序列模型对推荐系统的启发
- 3.10 强化学习与推荐系统的结合
  - 3.10.1 深度强化学习推荐系统框架
  - 3.10.2 深度强化学习推荐模型
  - 3.10.3 DRN的学习过程
  - 3.10.4 DRN的在线学习方法——竞争梯度下降算法
  - 3.10.5 强化学习对推荐系统的启发
- 3.11 总结——推荐系统的深度学习时代



第4章 Embedding技术在推荐系统中的应用

- 4.1 什么是Embedding
  - 4.1.1 词向量的例子
  - 4.1.2 Embedding 技术在其他领域的扩展
  - 4.1.3 Embedding 技术对于深度学习推荐系统的重要性
- 4.2 Word2vec——经典的Embedding方法
  - 4.2.1 什么是Word2vec
  - 4.2.2 Word2vec模型的训练过程
  - 4.2.3 Word2vec的“负采样”训练方法
  - 4.2.4 Word2vec对Embedding技术的奠基性意义
- 4.3 Item2vec——Word2vec 在推荐系统领域的推广
  - 4.3.1 Item2vec的基本原理
  - 4.3.2 “广义”的Item2vec
  - 4.3.3 Item2vec方法的特点和局限性
- 4.4 Graph Embedding——引入更多结构信息的图嵌入技术
  - 4.4.1 DeepWalk——基础的Graph Embedding方法
  - 4.4.2 Node2vec——同质性和结构性的权衡
  - 4.4.3 EGES——阿里巴巴的综合性Graph Embedding方法
- 4.5 Embedding与深度学习推荐系统的结合
  - 4.5.1 深度学习网络中的Embedding层
  - 4.5.2 Embedding的预训练方法
  - 4.5.3 Embedding作为推荐系统召回层的方法
- 4.6 局部敏感哈希——让Embedding插上翅膀的快速搜索方法
  - 4.6.1 “快速”Embedding近邻搜索
  - 4.6.2 局部敏感哈希的基本原理
  - 4.6.3 局部敏感哈希多桶策略
- 4.7 总结——深度学习推荐系统的核心操作



第5章 多角度审视推荐系统

- 5.1 推荐系统的特征工程
  - 5.1.1 构建推荐系统特征工程的原则
  - 5.1.2 推荐系统中的常用特征
  - 5.1.3 常用的特征处理方法
  - 5.1.4 特征工程与业务理解
- 5.2 推荐系统召回层的主要策略
  - 5.2.1 召回层和排序层的功能特点
  - 5.2.2 多路召回策略
  - 5.2.3 基于Embedding的召回方法
- 5.3 推荐系统的实时性
  - 5.3.1 为什么说推荐系统的实时性是重要的
  - 5.3.2 推荐系统“特征”的实时性
  - 5.3.3 推荐系统“模型”的实时性
  - 5.3.4 用“木桶理论”看待推荐系统的迭代升级
- 5.4 如何合理设定推荐系统中的优化目标
  - 5.4.1 YouTube以观看时长为优化目标的合理性
  - 5.4.2 模型优化和应用场景的统一性
  - 5.4.3 优化目标是和其他团队的接口性工作
- 5.5 推荐系统中比模型结构更重要的是什么
  - 5.5.1 有解决推荐问题的“银弹”吗
  - 5.5.2 Netflix对用户行为的观察
  - 5.5.3 观察用户行为，在模型中加入有价值的用户信息
  - 5.5.4 DIN模型的改进动机
  - 5.5.5 算法工程师不能只是一个“炼金术士”
- 5.6 冷启动的解决办法
  - 5.6.1 基于规则的冷启动过程
  - 5.6.2 丰富冷启动过程中可获得的用户和物品特征
  - 5.6.3 利用主动学习、迁移学习和“探索与利用”机制
  - 5.6.4 “巧妇难为无米之炊”的困境
- 5.7 探索与利用
  - 5.7.1 传统的探索与利用方法
  - 5.7.2 个性化的探索与利用方法
  - 5.7.3 基于模型的探索与利用方法
  - 5.7.4 “探索与利用”机制在推荐系统中的应用



第6章 深度学习推荐系统的工程实现

- 6.1 推荐系统的数据流

  - 6.1.1 批处理大数据架构
  - 6.1.2 流计算大数据架构
  - 6.1.3 Lambda架构
  - 6.1.4 Kappa架构
  - 6.1.5 大数据平台与推荐系统的整合

- 6.2 推荐模型离线训练之Spark MLlib

  - 6.2.1 Spark的分布式计算原理
  - 6.2.2 Spark MLlib的模型并行训练原理
  - 6.2.3 Spark MLlib并行训练的局限性

- 6.3 推荐模型离线训练之Parameter Server

  - 6.3.1 Parameter Server的分布式训练原理
  - 6.3.2 一致性与并行效率之间的取舍
  - 6.3.3 多server节点的协同和效率问题
  - 6.3.4 Parameter Server技术要点总结

- 6.4 推荐模型离线训练之TensorFlow

  - 6.4.1 TensorFlow的基本原理
  - 6.4.2 TensorFlow基于任务关系图的并行训练过程
  - 6.4.3 TensorFlow的单机训练与分布式训练模式
  - 6.4.4 TensorFlow技术要点总结

- 6.5 深度学习推荐模型的上线部署

  - 6.5.1 预存推荐结果或Embedding结果
  - 6.5.2 自研模型线上服务平台
  - 6.5.3 预训练Embedding+轻量级线上模型
  - 6.5.4 利用PMML转换并部署模型
  - 6.5.5 TensorFlow Serving
  - 6.5.6 灵活选择模型服务方法

- 6.6 工程与理论之间的权衡

  - 6.6.1 工程师职责的本质
  - 6.6.2 Redis容量和模型上线方式之间的权衡
  - 6.6.3 研发周期限制和技术选型的权衡
  - 6.6.4 硬件平台环境和模型结构间的权衡
  - 6.6.5 处理好整体和局部的关系

  

- 第7章 推荐系统的评估

- 7.1 离线评估方法与基本评价指标

  - 7.1.1 离线评估的主要方法
  - 7.1.2 离线评估的指标

- 7.2 直接评估推荐序列的离线指标

  - 7.2.1 P-R曲线
  - 7.2.2 ROC曲线
  - 7.2.3 平均精度均值
  - 7.2.4 合理选择评估指标

- 7.3 更接近线上环境的离线评估方法——Replay

  - 7.3.1 模型评估的逻辑闭环
  - 7.3.2 动态离线评估方法
  - 7.3.3 Netflix的Replay评估方法实践

- 7.4 A/B测试与线上评估指标

  - 7.4.1 什么是A/B测试
  - 7.4.2 A/B测试的“分桶”原则
  - 7.4.3 线上A/B测试的评估指标

- 7.5 快速线上评估方法——Interleaving

  - 7.5.1 传统A/B测试存在的统计学问题
  - 7.5.2 Interleaving方法的实现
  - 7.5.3 Interleaving方法与传统A/B测试的灵敏度比较
  - 7.5.4 Interleaving方法指标与A/B测试指标的相关性
  - 7.5.5 Interleaving方法的优点与缺点

- 7.6 推荐系统的评估体系

  

- 第8章 深度学习推荐系统的前沿实践

- 8.1 Facebook的深度学习推荐系统
  - 8.1.1 推荐系统应用场景
  - 8.1.2 以GBDT+LR组合模型为基础的CTR预估模型
  - 8.1.3 实时数据流架构
  - 8.1.4 降采样和模型校正
  - 8.1.5 Facebook GBDT+LR组合模型的工程实践
  - 8.1.6 Facebook的深度学习模型DLRM
  - 8.1.7 DLRM模型并行训练方法
  - 8.1.8 DLRM模型的效果
  - 8.1.9 Facebook深度学习推荐系统总结
- 8.2 Airbnb基于Embedding的实时搜索推荐系统
  - 8.2.1 推荐系统应用场景
  - 8.2.2 基于短期兴趣的房源Embedding方法
  - 8.2.3 基于长期兴趣的用户Embedding和房源Embedding
  - 8.2.4 Airbnb搜索词的Embedding
  - 8.2.5 Airbnb的实时搜索排序模型及其特征工程
  - 8.2.6 Airbnb实时搜索推荐系统总结
- 8.3 YouTube深度学习视频推荐系统
  - 8.3.1 推荐系统应用场景
  - 8.3.2 YouTube推荐系统架构
  - 8.3.3 候选集生成模型
  - 8.3.4 候选集生成模型独特的线上服务方法
  - 8.3.5 排序模型
  - 8.3.6 训练和测试样本的处理
  - 8.3.7 如何处理用户对新视频的偏好
  - 8.3.8 YouTube深度学习视频推荐系统总结
- 8.4 阿里巴巴深度学习推荐系统的进化
  - 8.4.1 推荐系统应用场景
  - 8.4.2 阿里巴巴的推荐模型体系
  - 8.4.3 阿里巴巴深度学习推荐模型的进化过程
  - 8.4.4 模型服务模块的技术架构
  - 8.4.5 阿里巴巴推荐技术架构总结



第9章 构建属于你的推荐系统知识框架

- 9.1 推荐系统的整体知识架构图
- 9.2 推荐模型发展的时间线
- 9.3 如何成为一名优秀的推荐工程师
  - 9.3.1 推荐工程师的4项能力
  - 9.3.2 能力的深度和广度
  - 9.3.3 推荐工程师的能力总结
- 后记