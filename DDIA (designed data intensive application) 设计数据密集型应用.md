2020 5-14
[TOC]
#### 第一章：可靠性，可扩展性，可维护性
- 现代越来越多应用是数据密集型(**data intensive**),而不是计算密集型(**computing intensive**),相比于CPU，数据的传输，更新的操作越来越成为瓶颈。  
这里用**数据系统**这个抽象词，统称数据库，缓存，索引等一系列相关但又迥异的工具。因为他们的界限正在变得越来越模糊，例如redis用数据存储作为消息队列。尤其是，这些功能在设计时就需要组合在一起考虑，作为应用程序开发者，常常也要充当数据系统设计者。
- 一个应用有**功能需求(functional requirements)**（以什么方式完成搜索，存储，处理数据等任务）和**非功能需求(nonfunctional)**（如安全性，可靠性，可扩展性）
- 本书着重考虑三个方面：
  - **可靠性**(Reliability)：在困境中仍可正常工作
  - **可扩展性**(Scalability)：有合理的办法应对系统（数据量，流量，复杂性）的增长
  - **可维护性**(Maintainability)：许多不同的人（不同角色）在不同生命周期，都能高效地工作（维护系统，使其适应新的场景）  

##### 可靠性
- 可靠粗略的理解是“即使出现问题，也能正确工作”，这个问题，或者错误，即**故障(fault)**，对应的是容错。==容错只有针对特定类型的错误才有意义==，不可能可以容忍任何错误。故障不同于**失效(failure)**，故障是一部分状态偏离标准，失效是系统整体停止服务。故障的概率不可能为零，容错机制要避免故障导致失效。平时故意触发故障可以提高容错机制的能力，  
- **硬件故障**在大规模的集群中很常见，从硬盘崩溃到机房断电，不得不考虑。硬盘本身**平均无故障时间(MTTF mean time to failure)** 约为10-50年,10000个硬盘的集群中，平均每天都有1个硬盘故障。硬件冗余是最常见的解决方法，如RAID和后备电源。云平台这类新应用在设计时就优先考虑**灵活性**和**弹性**,而非单机可靠性，那么在硬件冗余之上加入软件容错机制就在容忍硬件故障上更进一步了。  
- **软件错误**相比于硬件故障更加系统性，这种内部的**系统性错误(systematic error)**更难以预料，而且可能范围更大，如千年虫bug，失控进程占用过多资源，但这种程序中根本的错误没有完美的解决办法，只能用生产中更多的测试，更多的监控等小办法缓解。  
- **人为错误**，运维配置错误是导致服务中断的首要原因，需要在设计，测试，监控，配置，乃至管理方面优化。  

##### 可扩展性
- 可扩展性是指系统应对负载增长的能力。==这不是一个静态的属性，如某些变量可扩展，某些不可，那样讨论没有意义；而是一个动态的解决方案，即“如果系统以某种方式（用户量增加，用户数据累积）增长，如何应对？”，或者“如何增加计算资源处理额外的负载。”==  
- **描述负载**
    - 负载可以用**负载参数(load parameters)** 来描述，具体却取决于架构，如每秒请求，数据库读写比率，活跃用户数量等等，平均情况和极端情况哪个是优化目标也是依情况而定的。  
    - 用简化的推特为例来说明。推特的两个主要业务：发布推文（平均4.6k/s,峰值12k/s），查看时间线(平均300k/s)。
    - 每秒12k的写入还是容易处理的，而推特的扩展性挑战来自**扇出(fan-out)**，即每个用户关注了很多人，也被很多人关注。
    - 这种操作有两种实现方式
      1. 用关系数据库，用户查看主页时，查询关注的所有人发送推文按时间的合并。
      2. 为每个用户的主页维持一个缓存，像收件箱一样，一个用户发送推文时，对所有关注者的缓存发送这条推文。
    - 推特一开始使用方法1，后来转向方法2，因为发推文比查询主页操作少得多，因此应该在前者时做更多事情，后者时做更少。但是方法2也有缺点，就是一些粉丝很多的用户（名流），他们发的每一条推文都意味着对缓存的大量写入，这很难迅速完成。因此，推特最后主要采用方法2，但是对名流的推文采用方法1，最后将两者得到的时间线合并。  
- **描述性能**
  - 自然地，我们会希望知道两个问题：增加负载参数时
    1. 保持系统资源不变，系统性能将如何被影响。
    2. 保持系统性能不变，需要增加多少系统资源。
  - 对于hadoop这样的批处理系统，我们通常关心**吞吐量(throughput)**，即每秒处理的记录数量。对于在线系统，更重要的是**响应时间(response time)**，即发送请求到接受响应之间的时间。
  - ==现实中，响应时间不是一个数值，而是一个**数值分布**，因为各式各样的请求有不同的响应时间。== 我们因此统计一个服务的响应时间均值和百分位数（如99分位数，最慢的1%的响应时间）。异常值在这里是重要的，最慢的那些响应时间（**尾部延迟(tail latencies)**）非常重要，因为他们往往是数据最多，最有价值的客户。==亚马逊在描述内部服务时就用99.9分位数为准。==
  - 实践中，后端应用常常调用大量后端服务，此时用户请求响应时间由最慢的服务决定，也因此高分位数比平均速度更重要。
  - **排队延迟(queueing delay)**通常占了高分位点响应时间的很大一部分，服务器并行任务数有限，因此少量缓慢的请求就能阻碍后续请求，即**头部阻塞**效应.
  - 负载增加时，如果这是数量级的增长，那么各种方法很难起效，常常需要重新考虑架构了。**纵向扩展(scaliing up)**（转向更强大的机器）和**横向扩展(scaling out)**（将负载分散到许多小机器）是两种典型的思路，同时采用两种自然是最好的。 
  - **弹性(elastic)** 系统是指可以在检测到负载增加时自动增加计算资源，对应的是手动扩展。如果负载难以预测，弹性系统可能有用，否则手动扩展更简单可靠。
  - **无状态服务(stateless services)**是很容易跨机器部署的，而带状态数据系统的分布式部署则较为复杂。（当然，随着分布式系统越来越好，分布式数据系统可能成为未来的默认配置）
  - 大规模的系统架构通常是应用特定的，没有**万金油(magic scaling sauce)**。一个良好的可扩展架构，围绕着**假设(assumption)**建立：哪些操作常见？哪些罕见？
  
##### 可维护性
- ==软件的大部分开销不在最初的开发阶段，而是在持续的维护阶段==，包括修复漏洞，保持系统正常运行，调查失效，适配新平台，添加新功能等等。
- 但是，许多程序员不喜欢维护**祖传(legacy)** 系统，以下的设计原则可以减少维护期间的痛苦：
  1. 可操作性
  2. 简单性
  3. 可演化性
- **可操作性**：使运维团队易于保持系统平稳运行
  - 良好的可操作性意味着更轻松的日常工作，则运维团队能专注于高价值的事情。
- **简单性**：管理复杂度
  - 随着项目越来越大，代码往往变得非常复杂，难以理解。**复杂度(complexity)** 的各种症状如纠结的依赖关系，不一致的命名和术语，需要绕开的特例。用于消除额外复杂度的最好工具是**抽象(abstraction)**.
- **可演化性**：适应变化
  - 数据系统层面的敏捷性，适应在频繁变化的环境中开发软件。



#### 第二章：数据模型与查询语言

- 数据模型在软件开发中很重要，它不仅影响软件的编写方式，而且影响我们的**解题思路**。应用使用层层叠加的数据模型，每一个层次数据模型的关键问题是：如何用低一层的数据模型表示。如现实世界需要用对象，函数，数据结构来建模。数据结构存储时要用json格式或者表，图。乃至更低层次的抽象和规划。

##### 关系模型和文档模型

- 最著名的数据模型自然是SQL：数据被组织成**关系**（SQL中的**表**），每个关系是**元组**的无序集合

- 2010年代被提出时，NoSQL起初并没有涉及任何特定技术，而只是一个Twitter标签。由于种种原因，后来它被重新解释为Not Only SQL。但是其背后的驱动因素是客观存在的：

  - 需要比关系数据库更好的可扩展性，包括非常大的数据集和非常高的**写入吞吐量**。
  - 关系数据库对特定查询操作有限的支持（不能做或者太慢）
  - 受限于**关系模型(relational schemas)**需要更动态和有表现力的数据模型
  - 需要免费，开源

  不同应用有不同的需求，因此在可预见的将来，关系数据库不会被完全替代。这种想法被称为**混合持久化(polyglot persistence)**

-  ==对象关系不匹配是对关系数据库最普遍的批评==，尤其是面向对象的编程语言变得广泛的今天，模型之间的不连贯是笨拙的。比如对于一个人的简历，在规范的关系数据库中，任何==不唯一字段==（如职位，教育）都需要单独在另外一个表中作为外键被用户表引用。JSON文档则可以更合适地保存这些数据，JSON表示比关系数据库的多表模式具有更好的**局部性（locality）**，但是这种表示也隐含了一个树状结构。

- 我们会用ID来代替字符串储存，ID只在数据库中有意义，而对人类有意义的信息只存储在一处，其余都是**副本（duplicate）**，这使得更新那些信息时方便得多，而这也是数据库**规范化（normalization）**的关键思想。多对多关系和多对一关系在应用中是很常见的，而文档数据库对这种连接的支持却很弱。

- 实际的文档数据库在表示多对多和多对一关系时的做法和关系数据库没有根本的区别，即使用**文档引用**来表示这种关系。在LinkedIn的例子中，对公司，学校，其他用户的引用就采用了这种做法，而这在关系数据库中被称为**外键**。

- 文档模型中的架构灵活性

  - ==大多数文档数据库不会强制文档中的数据采用什么模式，有时被称为**无模式（schemaless）**，但**读时模式（schema-on-read）**可能更精确。与之对应的是写时模式，即关系数据库保证所有数据符合其模式。==
  - 这类似于编程语言中的动态类型检查与静态类型检查的对比。
  - 读时模式意味着想改变数据格式时，可以直接开始写入新格式的数据，修改代码保证新旧格式都可以被正确读取即可。
  - 反之则需要对数据库进行迁移，这可能很慢，有时候很难保证写操作的正确运行（数据的结构常常由外部决定）

- 文档通常是以连续字符串形式存储的，因此即使只需要访问一小部分也需要加载整个文档，对于上述的引用更是需要索引多个表。写入时通常也需要整个重写，因此文档一般需要保持比较小。

##### 数据查询语言

- SQL是一种**声明式**查询语言，与命令式语言相比，SQL的查询与关系代数中条件选择相对应，无序地返回所有符合某种条件的数据。命令式语言会告诉计算机以特定顺序执行某些操作，循环，判断等等。==声明式查询语言通常是更简洁和容易的，而且它隐藏了数据库引擎的实现细节==，这使得可能不对查询做任何更改而实现性能提升。声明式语言也更适合并行执行。
- 在web上，CSS就是声明式语言，而JavaScript是命令式语言，前者在操作样式（如网页颜色，字体等）时方便得多。声明式语言的优势不局限与数据库，尽管大多数编程语言是命令式的。
- MapReduce查询
  - MapReduce是一个Google推广的编程模型，用于在多台机器上批量处理大规模数据。一些NoSQL数据库也支持MapReduce查询，如MongoDB。
  - MapReduce介于声明式和命令式之间，查询的逻辑是代码片段，但这些片段会被重复性地调用。它使用Map函数和Reduce函数，这两个函数是受限的，它们必须是**纯**函数，即只使用传入的数据作为输入，而不执行额外的查询，也不能有副作用。不过MapReduce的功能仍然是强大的。
  - 另一个问题是两个函数的编写比较困难，因此MongoDB引入了叫做**聚合管道（aggregate pipeline）**的声明式查询语言，这其实和SQL没有本质区别。

##### 图数据模型

- TBD

#### 第三章：存储与检索

- ==数据库完成的最基础的两件事：把数据交给数据库，数据库存储起来；向数据库要数据，返回数据。==
- 第二章从程序员的角度看待这两件事，讲述了数据模型和查询语言。这里从数据库的视角重新审视这个问题，讨论数据库内部的存储于检索机制。我们需要了解许多可用的存储引擎，才能选择一个合适的，并协调存储引擎来适配工作负载。

##### 驱动数据库的数据结构

- 一个最简单的数据库可以用一个不断追加写入的日志实现，但这种情况下查找开销是O(n)，这显然是不可接受的。我们需要**索引（index）**的数据结构来更高效查找特定键的值，大致思想是保存一些额外的元数据作为路标。要注意到每个索引都会拖慢写入速度，这是存储系统一个重要的权衡。

- 哈希索引
  - 键值索引与字典类似，用**散列映射（hash map）**，每个键值对应数据的地址被保存在哈希表中。
  - 这里要注意的是数据在不断写入时常用追加写入，而不是用新值覆盖旧值，因为数据通常在磁盘上，而磁盘的顺序写入比随机写入快得多。日志增长到一定大小时我们可以执行压缩和分段合并操作来只保留每个键的最近值（对每个）。
  - 哈希表索引的局限性在于散列表必须能放入内存，如果键的数量很多，以至于哈希表有很多冲突，甚至不得不放入磁盘，哈希表索引就会变得很慢（哈希表需要大量随机访问）。
  - 哈希表索引也不能高效范围查询，即扫描一个范围内所有的键。
  
- SSTables和LSM树

  - SSTables即**排序字符串表（Sorted String Table）**，即对键排序且每个键在每个合并的段文件只出现一次。
  - 合并段是简单高效的，就像归并排序算法中那样。但查找某个键不用二分查找，而是保持一个稀疏的键值索引，并在目标键所在的两个地址偏移之间顺序查找。这种做法依然需要一个保存在内存中的表，不过比哈希索引需要的表小得多。
  - 构建SSTables的关键在于写入时先在内存中利用红黑树一类的数据结构保持数据的有序，即**内存表（memtable）**。当内存表大于某个阈值之后，将其写入磁盘。
  - **LSM树（Log Structured Merge Trees）**被设计来适应需要高写入吞吐量的服务，因为磁盘写入是连续的。

- 事务处理与在线分析

  - 传统意义上的数据库完成写入，读取，更新的事务性作业，这些工作与实际的商业活动，或者用户活动相对应，这种访问模式即**在线事务处理（OLTP，Online Transaction Processing）**。
- 但是现代的数据分析也依赖于数据库，这种分析例如“哪个商品与X品牌的啤酒最常同时购买？”，这种分析需要大量的扫描，汇总统计。这种访问模式即**在线分析处理（OLAP，Online Analytice Processing）**。
  - 其他区别在于性能需求一个要求高可用和低延迟，一个要求批量处理足够快；数据状态一个是最新状态的数据，一个是过去的历史事件；用户一个是终端用户，一个是数据分析师；数据集尺寸通常也有几个数量级的区别。
- **数据仓库（data warehouse）**是指一个单独的用于OLAP的数据库，通常数据是OLTP系统的一个副本，将数据导入仓库的过程称为**“抽取-转换-加载（ETL）”**
  - TBD

#### 第四章：编码与演化

- TBD

#### 第五章：复制

- 出于很多原因使我们需要复制数据，如使数据与用户物理上接近，提高容错率和可用性，拓展可接受请求的机器以便提高吞吐量。
- 复制的困难之处在于处理复制数据的**变更（change）**。三种流行的变更复制算法：**单领导者（single leader），多领导者（multi leader）和无领导者（leaderless）**。
- 复制一章提到的技术基于一个小数据集的假设，即单台机器可以保持整个数据集的副本。 

##### 领导者与追随者

- 存储数据库的每个节点称为副本（replica），数据的一致性是一个不可避免的问题。基于领导者的复制又被称**主从（master/slave）复制**。
- 这种复制有一个副本被指定为**领导者（leader）**，写入请求都被发送到领导者，领导者更新数据。其他副本即**跟随者(followers)**，也即**只读副本（read replica）或从库（slaves），热备（hot standby）**， 根据领导者写入时的复制日志或**变更流（change stream）**更新。从库都是只读的，领导者才能写入。
- **同步复制和异步复制**是复制系统的一个重要细节，**同步（synchronously）和异步（asynchronously）**

##### 复制的延迟

- ==基于主库的复制要求所有写入在主库处理，而只读查询可以由任何副本完成，适合读多写少的常见场景。==
  - 这种方法只适用于异步复制，如果尝试同步复制，则单个节点故障就会导致系统故障。这就导致从库常常会看到过时的信息，只拥有**最终一致性（eventually consistency）**。实践中，**复制延迟（replication lag）** 没有一个确保的上限。
- 读己之写
  - 用户对不同数据读写延迟的敏感度是不同的，用户可能希望在自己写之后立刻读到修改，但是对其他用户的写入延迟并不敏感。一个简单的方法就是，对用户能修改的数据在主库读，对其他在从库读。客户端可以对写操作进行记录，也可以判断从库够不够新。
  - 在一个用户有多个设备的情况，则更为复杂，总体来说，最好将同一个用户的副本放在一个数据中心。
- **单调读（Monotonic reads）** 是一种比强一致性弱，但比最终一致性强的保证，即用户可能会看到一个旧值，但他不会看到比之前看到的更旧的值。
  - **一致前缀读（consistent prefix reads）** 是一种相关的保证，即多个用户的写入可能是有因果关系的，如一个用户回复另一个用户，如果数据库对因果关系的后续的延迟显著小于前因，就会导致错乱。
- **事务（transaction）** 在传统数据库中就提供了保证数据库在复制问题上不会出错的保证，但在走向分布式数据库的过程中，我们需要替代方案。

##### 多主复制

- 



#### 第六章：分区

- **分区（partitions）** 是一种将大型数据库分成小型数据库，以便拥有更大吞吐量以适应更高负载的方法。

##### 分区与复制

- 分区和复制常常是结合使用的，使每个分区的副本存储在多个节点，每条记录属于一个分区，但存储在多个节点。

##### 键值数据的分区

- 分区的一个目标是将数据和查询负载均匀分布在各个节点上。分区可能是不公平的，即**偏斜（skew）** 现象。数据偏斜会降低分区的效率，高度不均衡导致的高负载分区被称为**热点（hot spot）**。
- 避免热点最简单的方法是将记录随机分配。但是这样在读取时我们就不得不查询所有分区，这显然不合适。
- 根据键的范围分区：键值模型可以为每个分区指定一块连续的键范围。在每个分区中，我们按照一定顺序保存键。但是这样其实有时也会导致热点，即当我们集中处理某一类数据（如某一天的数据）时，访问会集中在一个分区。
- 根据键的散列分区：一个合适的均匀的散列函数并不难找，这可以很好地避免偏斜和热点。但是这使得系统失去了高效范围查询的能力。Cassandra用了一种折中的策略，一个表由多个列组成的复合主键声明，第一列作为散列的根据，其他列顺序存储。
- 负载倾斜和消除热点：如果一个键可以被识别出非常高频（如一条名人的推特内容），可以在它后面添加一个随机数，并将一个主键分散为100或1000个不同的主键，存储在不同的分区中，这平衡了负载却也增加了读写开销。目前没有没有公认的算法决定什么情况下需要分割主键。

##### 分片和次级索引

- 次级索引是关系数据库的基础（想象在某个条件下SELECT），在键值数据库中暂时应用较少，但有增加的趋势。次级索引的一个问题是不能整齐地映射到分区，有两种分区方法：**基于文档**的分区和**基于关键字（term-based）** 的分区
- 基于文档的分区：每个分区可以构造一个独立的次级索引，对每一个**字段（field）** 构造一个映射表。这种查询方法也叫**分散/聚集（scatter/gather）。**MongoDB，Cassandra等很多数据库使用文档分区二级索引。
- 基于关键字的二级索引：构建一个全局索引，在分区之外保存每个字段的散列值。一个问题是这种全局二级索引的更新通常是异步的，因为在写入的同时更新需要跨分区的分布式事务。

##### 分区再平衡

- ==再平衡（rebalancing）指的是数据库发生变化时负载在节点间移动的过程，区别于运行时的消除热点。==
- hash mod N是一个反面案例，N在这里通常是节点数量，但是节点数每次修改时，几乎所有键所属的分区都会变化，需要昂贵的代价，这显然不是一个好方案。
- 固定数量分区：一种简单的方法是构建比节点数多一些的分区数，比如10个节点拥有1000个分区。增加新节点时只修改分区对应的节点，不修改键对应的分区。这种方法需要选择合适的分区数量，如果节点数改变了数十倍，这种方法显然很难适应。
- 动态分区：按键的方位进行分区

##### 请求路由

- 客户想要发出请求时，如何知道应该连接哪个节点？
- TODO

#### 第七章：事务

- 事务（transaction）是为了实现可靠性而诞生的机制，它将多个读写操作组合成一个逻辑单元，并将其视为一个操作。整个事务要么成功而提交（submit），要么失败而中止（abort）并回滚（rollback）。事务不仅可以解决错误的情况，也可以解决并发中产生的脏读，竞争等问题。
- 事务提供的安全保证，可以被描述为ACID，即原子性（atomicity），一致性（consistency），隔离性（isolation）和持久性（durability）。

#### 第八章：分布式系统的麻烦

##### 故障与部分失效

- 系统的某些部分可能以某种不可预知的方式被破坏，这被称为**部分失效（partial failure）**
- 与互联网和云计算相关的应用程序，相比于传统的预测天气一类的运行在超级计算机上的应用，对短时间的服务不可用都更加难以接受。
- 要使分布式系统工作，我们必须接受部分故障的可能性，并在软件中建立容错机制，从不可靠的组件构建可靠的系统。

##### 不可靠的网络

- 互联网和数据中心的内部网络都是**异步分组网络（asynchronous packet networks）**，这种情况下，节点可以向另一个节点发送消息，但是网络不保证到达。
- 很多种可能的导致没有得到响应的情况需要被区分，如请求丢失，目标节点关闭，响应丢失，请求或响应尚在排队。通常的处理方法是**超时（timeout）**，即在一段时间之后放弃等待。
- EC2即Elastic Compute Cloud，弹性计算云，是一个让使用者可以弹性地运行自己的（amazon）机器映像档的云服务。这种公有云服务实际上并不稳定，远不如管理良好的私有数据中心，因此对**网络故障（network fault）**的错误处理是必不可少的。
- 通过网络判断一个节点是否工作是很困难的，有时很明显故障了，但更多的时候只能在超时并重试几次之后关闭节点。
- 超时应该等待多久并没有简单的答案，理论上如果传输和节点处理请求的时间有保证，可以用这个保证的时间长度作为超时阈值，但一般没有这种保证。
- TCP有重传机制，也利用超时判定。但一些对延迟敏感的应用使用UDP，因为此时重传而延迟的数据毫无价值。==故障检测延迟与过早超时风险之间总是需要折中的。==
- 

##### 一致性与共识

- 分布式中的一致性可能是最常被提起的一致性。就是两个节点在同一时刻可能拥有不同的数据。
- 大部分复制的数据库至少提供**最终一致性**，这很弱。数据库表面上看起来像一个可以读写的变量，但实际上他有更复杂的语义。
- 分布式一致性模型是面对==延迟==和故障时，如何协调副本间的状态。而事务隔离是为了避免由于同时指向事务而导致的竞争状态。

##### 线性一致性

- 线性一致性（linearizability）背后的想法是利用
- 



















































